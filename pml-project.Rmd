---
title: "PML_Project"
author: "unkame"
date: "Sunday, June 21, 2015"
output: html_document
fontsize: 10 pt
---

## Objective
Objective of this project was to create a prediction model to predict the manner in which the testers did the weight lifted exercise. The model would also be applied to 20 different test cases to testify its accuracy.

## Background
People would regularly quantify how much of a particular activity they did, but they rarely quantify how well they did it. The project this time would be carried out to study the motions of doing exercises. Accelerometers would be attached on the bely, forearm, arm, and dumbbell of 6 participants to collect data during they were exercising. They would be asked to perform barbell lifts correctly and incorrectly in 5 different ways. Data were collected and classified as training and testing data sets. "classe" variable in the training set was the prediction target. Other variables would be studied and used to build the model.

## Data Preparations
Data were prepared and separated into:
1. training set: "pml-training.csv"
2. testing set: "pml-testing.csv"

Data loading:
Following codes were to load the data, interpreting the values "NA", "#DIV/0!" and empty in data as NA:
```{r}
training <- read.csv("pml-training.csv", na.strings = c("NA", "#DIV/0!", ""))
testing  <- read.csv("pml-testing.csv",  na.strings = c("NA", "#DIV/0!", ""))
```

The description of data loaded was:
```{r}
str(training, list.len=10)
```

And the variable "classe" was:
```{r}
table(training$classe)
```


Data Cleaning:

Values in column 1 to 6 were the descriptive information of the data, so they could be removed. Also the columns in which the values were mostly "NA" should be removed.
```{r}
training <- training[, 7:160]
testing  <- testing[, 7:160]
is_data  <- apply(!is.na(training), 2, sum) > 19622 - 1
training <- training[, is_data]
testing  <- testing[, is_data]
```


Cross Validation:

In order to build the model, here the training data sets would be split for cross validation. The proportion of splitted training and testing sets were 3:2.
```{r, message=FALSE, warning=FALSE}
library(caret)  ##library required
set.seed(1234)
inTrain <- createDataPartition(y=training$classe, p=0.60, list=FALSE)
train1  <- training[inTrain,]
train2  <- training[-inTrain,]
```

Then zero covariates were identified using function "nearZeroVar", and consequently removed:
```{r}
nzv_cols <- nearZeroVar(train1)
if(length(nzv_cols) > 0) {
  train1 <- train1[, -nzv_cols]
  train2 <- train2[, -nzv_cols]
}
```

The data sets of "train1" and "train2" were made. Both sets had 53 covariates, which might be used to build the model.
```{r}
dim(train1); dim(train2)
```

## Data Analysis - Random Forest
Method "Random Forest" was used to find out the suitable variables to build the model. 
```{r, message=FALSE, warning=FALSE}
library(randomForest) ## library required
set.seed(1234)
fitModel <- randomForest(classe~., data=train1, importance=TRUE, ntree=100)
varImpPlot(fitModel)
```

charts of variable importance were shown. To reduce using 53 variables, the best 10 variables in both graphs would be chosen to build the model. Following 10 variables were selected: yaw_belt, roll_belt, num_window, pitch_belt, magnet_dumbbell_y, magnet_dumbbell_z, pitch_forearm, accel_dumbbell_y, roll_arm, and roll_forearm. 

The correlations of those 10 variables were:
```{r, message=FALSE, warning=FALSE}
correl = cor(train1[,c("yaw_belt","roll_belt","num_window","pitch_belt","magnet_dumbbell_z","magnet_dumbbell_y","pitch_forearm","accel_dumbbell_y","roll_arm","roll_forearm")])
diag(correl) <- 0
which(abs(correl)>0.75, arr.ind=TRUE)
```

And the result showed that there was problem within variables "roll_belt" and "yaw_belt". Either one of them should be removed.

A tree method Recursive Partitioning and Regression Trees (rpart model) was used to examine the covariates within the data sets. Obviously
```{r, message=FALSE, warning=FALSE}
library(rpart.plot)  ## library required
fitModel <- rpart(classe~., data=train1, method="class")
prp(fitModel, cex=0.6)
```

Obviously, the tree selected "roll_belt" as first discriminant. So "roll_belt" should be more important than "yaw_belt". "yaw_belt" would be eliminated.

## Modeling
9 variables were selected to build this model: roll_belt, num_window, pitch_belt, magnet_dumbbell_y, magnet_dumbbell_z, pitch_forearm, accel_dumbbell_y, roll_arm, and roll_forearm. The model building method used was also "Random Forest".
```{r, eval=FALSE, message=FALSE, warning=FALSE}
set.seed(1234)
fitModel <- train(classe~roll_belt+num_window+pitch_belt+magnet_dumbbell_y+magnet_dumbbell_z+pitch_forearm+accel_dumbbell_y+roll_arm+roll_forearm, 
                  data=train1, 
                  method="rf", 
                  trControl=trainControl(method="cv", number=2), 
                  prox=TRUE, 
                  verbose=TRUE, 
                  allowParallel=TRUE)
```
```{r, echo=FALSE}
set.seed(1234)
fitModel <- readRDS("modelRF.Rds")
```


Accuracy testing:

To primarily test the accuracy of the model, confusionMatrix() function was used to data set "train2".
```{r, message=FALSE, warning=FALSE}
predictions <- predict(fitModel, newdata=train2)
confusionMat <- confusionMatrix(predictions, train2$classe)
confusionMat$overall[1]
```

The accuracy displayed was 99.62%. It should be high enough to positively validate the predictability of the model. Therefore the estimation of out of sample error rate would be 100% - 99.62% = 0.38%

## Predictions on the testing data set
The model was used to predict result by testing data set from "pml-testing.csv".
```{r}
predictions <- predict(fitModel, newdata=testing)
predictions
```
(After submission, all 20 test cases were passed.)

```{r, eval=FALSE, echo=FALSE}
testing$classe <- predictions
## save the prediction result in csv file
submit <- data.frame(problem_id = testing$problem_id, classe = predictions)
write.csv(submit, file = "coursera-submission.csv", row.names = FALSE)

## save the prediction result in 20 txt file for submission
answers = testing$classe
write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_",i,".txt")
    write.table(x[i], file=filename, quote=FALSE, row.names=FALSE, col.names=FALSE)
  }
}
write_files(answers)
```

## Conclusion
A predictive model was built using "Random Forest" method. Through "Random Forest" algorithm and "Rpart" model, the covariates selected in the model were roll_belt, num_window, pitch_belt, magnet_dumbbell_y, magnet_dumbbell_z, pitch_forearm, accel_dumbbell_y, roll_arm, and roll_forearm. The model had 99.62% accuracy. All the 20 test cases were passed.


